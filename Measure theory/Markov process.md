
# Definition: Markov process/chain

**Type:** #definition  

## Definition
- Using a [[Markov kernel]]/[[Transition kernel]] $K$ we define a markov process as follows:
	- discrete: $P(X_{n+1}\in A|X_{n}=x)=K(x,A)$
	- continuous: $P(X_{t}\in A|X_{0}=x)=K_{t}(x,A)$ with transition [[Operator|operators]] $p_{t}$
		- These $K_{t}$ satisfy
			- [[Chapman-Kolmogorov]]
			- [[Measurability]]
			- Stochastic [[Completeness]] (if needed)
			- [[Conservativity]] (sometimes)

## Intuition (optional)


## Equivalent Formulations (optional)


## Related Concepts

